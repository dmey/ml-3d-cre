{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, HTML\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import io\n",
    "import pickle\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = 'median'\n",
    "metric = 'mae'\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "results_dir = root_dir / 'results'\n",
    "\n",
    "def get_job_stats_dir(job_name, variant):\n",
    "    return results_dir / f'job_stats_{job_name}_{variant}'\n",
    "\n",
    "def get_notebooks_dir(job_name, variant):\n",
    "    return results_dir / 'notebooks' / f'{job_name}_{variant}'\n",
    "\n",
    "def load_stats(job_name, variant):\n",
    "    pkl_dir = get_job_stats_dir(job_name, variant)\n",
    "    pkls = [pickle.load(open(p, 'rb')) for p in sorted(pkl_dir.glob('*.pkl'))]\n",
    "    assert len(pkls) > 0, f'No stats found in {pkl_dir}!'\n",
    "    stats = pd.concat(pkls)\n",
    "    stats['var_synth_count'] = stats.apply(lambda x: x['var_synth'].count(',') + 1, axis=1)\n",
    "    stats['var_ml_count'] = stats.apply(lambda x: x['var_ml'].count(',') + 1, axis=1)\n",
    "    stats['synth_enabled'] = stats.apply(lambda x: 'Yes' if x['synth_mul_factor'] else 'No', axis=1)\n",
    "    return stats\n",
    "\n",
    "def select_best_across_iterations(df_stats, column: str, method: str):\n",
    "    def fn(df):\n",
    "        df_sorted = df.sort_values(by=[column])\n",
    "        if method == 'min':\n",
    "            row = df_sorted.head(1)\n",
    "        elif method == 'median':\n",
    "            row = df_sorted.iloc[[len(df) // 2]]\n",
    "        row = row.drop(columns=['name'])\n",
    "        return row\n",
    "    df_best = df_stats.groupby(['name']).apply(fn)\n",
    "    df_best = df_best.reset_index()\n",
    "    df_best = df_best.drop(columns=['level_1']) # introduced during groupby\n",
    "    return df_best\n",
    "           \n",
    "def print_tables(stats):\n",
    "    display(Markdown(f'## Table: unaggregated sorted by `lw_{metric}_test`'))\n",
    "    display(stats.sort_values(by=[f'lw_{metric}_test']))\n",
    "    display(Markdown(f'## Table: unaggregated sorted by `sw_{metric}_test`'))\n",
    "    display(stats.sort_values(by=[f'sw_{metric}_test']))\n",
    "\n",
    "    # Summary statistics aggregated over all iterations per configuration\n",
    "    # Sorted by M*E Test (LW and SW)\n",
    "    lw_agg_stats = select_best_across_iterations(stats, f'lw_{metric}_test', aggregation)\n",
    "    sw_agg_stats = select_best_across_iterations(stats, f'sw_{metric}_test', aggregation)\n",
    "    \n",
    "    display(Markdown(f'## Table: aggregated by `name` and sorted by `lw_{metric}_test`'))\n",
    "    display(lw_agg_stats.sort_values(by=[f'lw_{metric}_test']))\n",
    "    display(Markdown(f'## Table: aggregated by `name` and sorted by `sw_{metric}_test`'))\n",
    "    display(sw_agg_stats.sort_values(by=[f'sw_{metric}_test']))\n",
    "    \n",
    "def draw_heatmap(stats, x, y, x_label=None, y_label=None):\n",
    "    x_label = x_label or x\n",
    "    y_label = y_label or y\n",
    "    cbar_label = 'Flux'\n",
    "\n",
    "    display(Markdown(f'## Heatmap: aggregated by `{x}` & `{y}`'))\n",
    "    agg_stats = stats.groupby([x, y]).agg(aggregation)\n",
    "    agg_stats = agg_stats.reset_index()\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    sns.heatmap(agg_stats.pivot(y, x, f'sw_{metric}_test'), ax=axs[0])\n",
    "    axs[0].set_title(f'Shortwave {metric.upper()}')\n",
    "\n",
    "    sns.heatmap(agg_stats.pivot(y, x, f'lw_{metric}_test'), ax=axs[1])\n",
    "    axs[1].set_title(f'Longwave {metric.upper()}')\n",
    "\n",
    "    for j in [0, 1]:\n",
    "        ax = axs[j]\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label if j == 0 else '')\n",
    "        if j == 1:            \n",
    "            ax.collections[0].colorbar.set_label(cbar_label)\n",
    "    plt_show_svg()\n",
    "\n",
    "x_labels = {\n",
    "    'hidden_size': 'Hidden size',\n",
    "    'synth_enabled': 'Data augmentation'\n",
    "}\n",
    "    \n",
    "def draw_boxplots(stats, ylim=None):\n",
    "    display(Markdown(f'## Boxplots'))\n",
    "    var_names = ['hidden_size', 'n_hidden_layers', 'synth_mul_factor', 'synth_enabled', 'unif_ratio', 'stretch_factor', 'loss', 'activation', 'l1_penalty', 'l2_penalty', 'var_regularizer_factor', 'dropout_ratio', 'var_synth_count', 'var_ml_count']\n",
    "    for var_name in var_names:\n",
    "        if var_name not in stats:\n",
    "            continue\n",
    "        if len(stats.groupby([var_name]).agg(aggregation)) == 1:\n",
    "            continue\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "        plot = sns.boxplot(x=var_name, y=f\"sw_{metric}_test\", data=stats, ax=axs[0])\n",
    "        plot.set(\n",
    "            xlabel=x_labels.get(var_name, var_name),\n",
    "            ylabel=\"Shortwave mean absolute error in W m⁻²\",\n",
    "            ylim=ylim\n",
    "        )        \n",
    "        plot = sns.boxplot(x=var_name, y=f\"lw_{metric}_test\", data=stats, ax=axs[1])\n",
    "        plot.set(\n",
    "            xlabel=x_labels.get(var_name, var_name),\n",
    "            ylabel=\"Longwave mean absolute error in W m⁻²\",\n",
    "            ylim=ylim\n",
    "        )\n",
    "        plt_show_svg()\n",
    "\n",
    "def plt_show_svg(fig=None):\n",
    "    from IPython.display import HTML\n",
    "    if fig is not None and hasattr(fig, 'to_image'):\n",
    "        # plotly\n",
    "        svg = fig.to_image(format=\"svg\")\n",
    "    else:\n",
    "        if fig is None:\n",
    "            fig = plt.gcf()\n",
    "        f = io.BytesIO()\n",
    "        fig.savefig(f, format='svg', bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        svg = f.getvalue()\n",
    "    svg_url = 'data:image/svg+xml;base64,' + base64.b64encode(svg).decode()\n",
    "    display(HTML(f'<img src=\"{svg_url}\"></img>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job: main_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = load_stats(job_name='mlp', variant='default')\n",
    "\n",
    "print_tables(stats)\n",
    "\n",
    "draw_heatmap(stats, x='hidden_size', y='n_hidden_layers', x_label='Hidden size', y_label='Hidden layers')\n",
    "\n",
    "draw_boxplots(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def with_noise(df):\n",
    "    stats_with_noise = df.copy()\n",
    "    stats_with_noise['var_ml_count'] += np.random.normal(0, 0.1, len(stats_with_noise))\n",
    "    stats_with_noise['n_hidden_layers'] += np.random.normal(0, 0.1, len(stats_with_noise))\n",
    "    stats_with_noise['hidden_size'] += np.random.normal(0, 0.05, len(stats_with_noise))\n",
    "    stats_with_noise['l1_penalty'] += np.random.normal(0, 0.000005, len(stats_with_noise))\n",
    "    stats_with_noise['l2_penalty'] += np.random.normal(0, 0.000005, len(stats_with_noise))\n",
    "    return stats_with_noise\n",
    "\n",
    "columns = {\n",
    "    'var_ml_count': 'Input quantities',\n",
    "    'n_hidden_layers': 'Hidden layers',\n",
    "    'hidden_size': 'Hidden size',\n",
    "    'l1_penalty': 'L1',\n",
    "    'l2_penalty': 'L2',\n",
    "    'sw_mae_test': 'Shortwave mean absolute error in W m⁻²',\n",
    "    'lw_mae_test': 'Longwave mean absolute error in W m⁻²',\n",
    "}\n",
    "column_names = list(columns.values())\n",
    "column_names.remove(columns['sw_mae_test'])\n",
    "column_names.remove(columns['lw_mae_test'])\n",
    "\n",
    "def rename_cols(df):\n",
    "    return df.rename(columns=columns)\n",
    "\n",
    "px_kw = dict(\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "    dimensions=column_names\n",
    ")\n",
    "\n",
    "display(Markdown(f'## SW: all data'))\n",
    "sw_stats_with_noise = with_noise(stats)\n",
    "px.parallel_coordinates(rename_cols(sw_stats_with_noise), color=columns[f\"sw_{metric}_test\"], \n",
    "                        **px_kw).show()\n",
    "\n",
    "display(Markdown(f'## SW: aggregated over iterations'))\n",
    "sw_stats_with_noise = with_noise(select_best_across_iterations(stats, f'sw_{metric}_test', aggregation))\n",
    "px.parallel_coordinates(rename_cols(sw_stats_with_noise), color=columns[f\"sw_{metric}_test\"], \n",
    "                        **px_kw).show()\n",
    "\n",
    "display(Markdown(f'## LW: all data'))\n",
    "lw_stats_with_noise = with_noise(stats)\n",
    "px.parallel_coordinates(rename_cols(lw_stats_with_noise), color=columns[f\"lw_{metric}_test\"], \n",
    "                        **px_kw).show()\n",
    "\n",
    "display(Markdown(f'## LW: aggregated over iterations'))\n",
    "lw_stats_with_noise = with_noise(select_best_across_iterations(stats, f'lw_{metric}_test', aggregation))\n",
    "px.parallel_coordinates(rename_cols(lw_stats_with_noise), color=columns[f\"lw_{metric}_test\"], \n",
    "                        **px_kw).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job: synth_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = load_stats(job_name='mlp', variant='synthia')\n",
    "\n",
    "print_tables(stats)\n",
    "\n",
    "draw_boxplots(stats, ylim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dir = get_notebooks_dir(job_name='mlp', variant='synthia')\n",
    "\n",
    "for xw in ['sw', 'lw']:\n",
    "    stats_sorted = stats[stats['synth_mul_factor'] > 0].sort_values(by=[f'{xw}_{metric}_test'])\n",
    "    median_idx = len(stats_sorted) // 2 -1\n",
    "    row = stats_sorted[median_idx:median_idx+1]\n",
    "    iteration = int(row.iteration)\n",
    "    for p in glob.glob(str(nb_dir / '*.txt')):\n",
    "        with open(p) as f:\n",
    "            content = f.read()\n",
    "            if f'iteration={iteration}' in content:\n",
    "                display(Markdown(f'## {xw}'))\n",
    "                display(row)\n",
    "                print(p.replace(\"txt\", \"html\"))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
